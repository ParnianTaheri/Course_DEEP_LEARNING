{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PfUFWxTpAMmx",
        "outputId": "81f4c829-42ab-40f6-ed76-1ff430217b74"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/albumentations/__init__.py:24: UserWarning: A new version of Albumentations is available: 2.0.3 (you have 1.4.20). Upgrade using: pip install -U albumentations. To disable automatic update checks, set the environment variable NO_ALBUMENTATIONS_UPDATE to 1.\n",
            "  check_for_updates()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "Collecting ultralytics\n",
            "  Downloading ultralytics-8.3.71-py3-none-any.whl.metadata (35 kB)\n",
            "Requirement already satisfied: numpy<=2.1.1,>=1.23.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (1.26.4)\n",
            "Requirement already satisfied: matplotlib>=3.3.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (3.10.0)\n",
            "Requirement already satisfied: opencv-python>=4.6.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (4.10.0.84)\n",
            "Requirement already satisfied: pillow>=7.1.2 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (11.1.0)\n",
            "Requirement already satisfied: pyyaml>=5.3.1 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (6.0.2)\n",
            "Requirement already satisfied: requests>=2.23.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (2.32.3)\n",
            "Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (1.13.1)\n",
            "Requirement already satisfied: torch>=1.8.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (2.5.1+cu124)\n",
            "Requirement already satisfied: torchvision>=0.9.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (0.20.1+cu124)\n",
            "Requirement already satisfied: tqdm>=4.64.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (4.67.1)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from ultralytics) (5.9.5)\n",
            "Requirement already satisfied: py-cpuinfo in /usr/local/lib/python3.11/dist-packages (from ultralytics) (9.0.0)\n",
            "Requirement already satisfied: pandas>=1.1.4 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (2.2.2)\n",
            "Requirement already satisfied: seaborn>=0.11.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (0.13.2)\n",
            "Collecting ultralytics-thop>=2.0.0 (from ultralytics)\n",
            "  Downloading ultralytics_thop-2.0.14-py3-none-any.whl.metadata (9.4 kB)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (4.55.7)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.4.8)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (24.2)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (3.2.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.1.4->ultralytics) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.1.4->ultralytics) (2025.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.23.0->ultralytics) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.23.0->ultralytics) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.23.0->ultralytics) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.23.0->ultralytics) (2024.12.14)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (3.17.0)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (3.1.5)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (2024.10.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch>=1.8.0->ultralytics)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch>=1.8.0->ultralytics)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch>=1.8.0->ultralytics)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch>=1.8.0->ultralytics)\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch>=1.8.0->ultralytics)\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch>=1.8.0->ultralytics)\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch>=1.8.0->ultralytics)\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch>=1.8.0->ultralytics)\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch>=1.8.0->ultralytics)\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch>=1.8.0->ultralytics)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: triton==3.1.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (3.1.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=1.8.0->ultralytics) (1.3.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib>=3.3.0->ultralytics) (1.17.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=1.8.0->ultralytics) (3.0.2)\n",
            "Downloading ultralytics-8.3.71-py3-none-any.whl (914 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m914.9/914.9 kB\u001b[0m \u001b[31m51.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m91.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m27.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m41.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m1.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m14.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m70.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ultralytics_thop-2.0.14-py3-none-any.whl (26 kB)\n",
            "Installing collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, ultralytics-thop, ultralytics\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import cv2\n",
        "import torch\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import albumentations as A\n",
        "from albumentations.pytorch import ToTensorV2\n",
        "import matplotlib.pyplot as plt\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from sklearn.model_selection import train_test_split\n",
        "import shutil\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "!pip install ultralytics\n",
        "!wget -O yolov8s.pt https://github.com/ultralytics/assets/releases/download/v0.0.0/yolov8s.pt"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Why Choose YOLO?**\n",
        "\n",
        "Yolo is extremely fast (real-time detection) with respect to R-CNN Faster. It is also optimized for video processing (e.g., sports tracking, self-driving cars) and it is lighter and can run on edge devices (mobile, embedded systems).\n",
        "\n",
        "Although it's accuracy is not as high as R-CNN Faster, I chose this model because the advantages outweigh, especially it's speed.\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "YT2j8P91M8Jb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import kagglehub\n",
        "\n",
        "# Download latest version\n",
        "path = kagglehub.dataset_download(\"ayushspai/sportsmot/versions/1\")\n",
        "\n",
        "print(\"Path to dataset files:\", path)\n",
        "\n",
        "# Move data from it's directory to colab\n",
        "!mv {path} /content/SportsMOT\n",
        "print(\"Dataset moved to /content/SportsMOT\")"
      ],
      "metadata": {
        "id": "NAenmZ1lO_1P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "football_videos = []\n",
        "with open(\"/content/SportsMOT/sportsmot_publish/splits_txt/football.txt\", \"r\") as f:\n",
        "    football_videos = [line.strip() for line in f.readlines()]\n",
        "\n",
        "print(\"Football Video Files:\", football_videos[:5])  # Show first 5 filenames"
      ],
      "metadata": {
        "id": "DK3TBVrWPAwD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import shutil\n",
        "\n",
        "dataset_root = \"SportsMOT/sportsmot_publish/dataset\"\n",
        "\n",
        "train_dir = os.path.join(dataset_root, \"train\")\n",
        "val_dir = os.path.join(dataset_root, \"val\")\n",
        "test_dir = os.path.join(dataset_root, \"test\")\n",
        "\n",
        "filtered_train_dir = os.path.join(dataset_root, \"train_football\")\n",
        "filtered_val_dir = os.path.join(dataset_root, \"val_football\")\n",
        "filtered_test_dir = os.path.join(dataset_root, \"test_football\")\n",
        "\n",
        "for path in [filtered_train_dir, filtered_val_dir, filtered_test_dir]:\n",
        "    os.makedirs(path, exist_ok=True)\n",
        "\n",
        "def filter_and_copy_football_videos(original_dir, filtered_dir, football_videos):\n",
        "    for folder in os.listdir(original_dir):\n",
        "        if folder in football_videos:\n",
        "            src_path = os.path.join(original_dir, folder)\n",
        "            dest_path = os.path.join(filtered_dir, folder)\n",
        "            shutil.copytree(src_path, dest_path, dirs_exist_ok=True)\n",
        "            print(f\"Copied: {folder}\")\n",
        "\n",
        "filter_and_copy_football_videos(train_dir, filtered_train_dir, football_videos)\n",
        "filter_and_copy_football_videos(val_dir, filtered_val_dir, football_videos)\n",
        "filter_and_copy_football_videos(test_dir, filtered_test_dir, football_videos)\n",
        "\n",
        "print(\"Football dataset filtering complete!\")\n"
      ],
      "metadata": {
        "id": "iAXljLoWPAqh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def convert_mot_to_yolo(video_list, dataset_split):\n",
        "    dataset_path = f\"SportsMOT/sportsmot_publish/dataset/{dataset_split}_football\"\n",
        "    yolo_labels_path = f\"SportsMOT/sportsmot_publish/dataset/{dataset_split}_football/labels\"\n",
        "\n",
        "    os.makedirs(yolo_labels_path, exist_ok=True)\n",
        "\n",
        "    for video in video_list:\n",
        "        gt_path = os.path.join(dataset_path, video, \"gt\", \"gt.txt\")\n",
        "        img_path = os.path.join(dataset_path, video, \"img1\")\n",
        "\n",
        "        if not os.path.exists(gt_path):\n",
        "            print(f\"Skipping {video}: No gt.txt found!\")\n",
        "            continue\n",
        "\n",
        "        gt_df = pd.read_csv(gt_path, header=None)\n",
        "        gt_df.columns = [\"frame_id\", \"object_id\", \"x\", \"y\", \"width\", \"height\", \"confidence\", \"class\", \"visibility\"]\n",
        "\n",
        "        for frame_id in gt_df[\"frame_id\"].unique():\n",
        "            frame_data = gt_df[gt_df[\"frame_id\"] == frame_id]\n",
        "\n",
        "            # YOLO label file per frame\n",
        "            label_filename = os.path.join(yolo_labels_path, f\"{frame_id:06d}.txt\")\n",
        "            with open(label_filename, \"w\") as f:\n",
        "                for _, row in frame_data.iterrows():\n",
        "                    x_center = (row[\"x\"] + row[\"width\"] / 2) / 1280  # Normalize x (width = 1280)\n",
        "                    y_center = (row[\"y\"] + row[\"height\"] / 2) / 720   # Normalize y (height = 720)\n",
        "                    width = row[\"width\"] / 1280\n",
        "                    height = row[\"height\"] / 720\n",
        "                    class_id = int(row[\"class\"])  # Use class ID\n",
        "\n",
        "                    f.write(f\"{class_id} {x_center:.6f} {y_center:.6f} {width:.6f} {height:.6f}\\n\")\n",
        "\n",
        "        print(f\"Converted: {video}\")\n",
        "\n",
        "\n",
        "convert_mot_to_yolo(os.listdir(\"SportsMOT/sportsmot_publish/dataset/train_football\"), \"train\")\n",
        "convert_mot_to_yolo(os.listdir(\"SportsMOT/sportsmot_publish/dataset/val_football\"), \"val\")\n",
        "convert_mot_to_yolo(os.listdir(\"SportsMOT/sportsmot_publish/dataset/test_football\"), \"test\")\n",
        "\n",
        "print(\"✅ MOT → YOLO label conversion complete!\")\n"
      ],
      "metadata": {
        "id": "dBoECz_uPAnZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# YOLO dataset paths\n",
        "yolo_train_path = \"SportsMOT/sportsmot_publish/dataset/yolo/train\"\n",
        "yolo_val_path = \"SportsMOT/sportsmot_publish/dataset/yolo/val\"\n",
        "yolo_test_path = \"SportsMOT/sportsmot_publish/dataset/yolo/test\"\n",
        "\n",
        "for path in [yolo_train_path, yolo_val_path, yolo_test_path]:\n",
        "    os.makedirs(os.path.join(path, \"images\"), exist_ok=True)\n",
        "    os.makedirs(os.path.join(path, \"labels\"), exist_ok=True)\n",
        "\n",
        "def move_and_rename_files(video_list, dataset_split):\n",
        "    dataset_path = f\"SportsMOT/sportsmot_publish/dataset/{dataset_split}\"\n",
        "    yolo_path = f\"SportsMOT/sportsmot_publish/dataset/yolo/{dataset_split.replace('_football', '')}\"  # Convert train_football → train\n",
        "\n",
        "    for video in video_list:\n",
        "        img_src = os.path.join(dataset_path, video, \"img1\")\n",
        "        label_src = os.path.join(dataset_path, \"labels\")\n",
        "\n",
        "        img_dest = os.path.join(yolo_path, \"images\")\n",
        "        label_dest = os.path.join(yolo_path, \"labels\")\n",
        "\n",
        "        os.makedirs(img_dest, exist_ok=True)\n",
        "        os.makedirs(label_dest, exist_ok=True)\n",
        "\n",
        "        # Rename and copy images\n",
        "        if os.path.exists(img_src):\n",
        "            for img in os.listdir(img_src):\n",
        "                new_img_name = f\"{video}_{img}\"\n",
        "                shutil.copy(os.path.join(img_src, img), os.path.join(img_dest, new_img_name))\n",
        "            print(f\"Moved and renamed images for: {video}\")\n",
        "        else:\n",
        "            print(f\"Skipping images: {video} (img1/ folder not found)\")\n",
        "\n",
        "        # Rename and copy labels\n",
        "        if os.path.exists(label_src):\n",
        "            for lbl in os.listdir(label_src):\n",
        "                new_lbl_name = f\"{video}_{lbl}\"  # Rename: v_1yHWGw8DH4A_c029_000001.txt\n",
        "                shutil.copy(os.path.join(label_src, lbl), os.path.join(label_dest, new_lbl_name))\n",
        "            print(f\"Moved and renamed labels for: {video}\")\n",
        "        else:\n",
        "            print(f\"Skipping labels: {video} (labels/ folder not found)\")\n",
        "\n",
        "move_and_rename_files(os.listdir(\"SportsMOT/sportsmot_publish/dataset/train_football\"), \"train_football\")\n",
        "move_and_rename_files(os.listdir(\"SportsMOT/sportsmot_publish/dataset/val_football\"), \"val_football\")\n",
        "move_and_rename_files(os.listdir(\"SportsMOT/sportsmot_publish/dataset/test_football\"), \"test_football\")\n",
        "\n",
        "print(\"YOLO dataset organized correctly with unique filenames.\")"
      ],
      "metadata": {
        "id": "1lq05IqUPSwo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset_yaml = \"\"\"\n",
        "path: /content/SportsMOT/sportsmot_publish/dataset/yolo\n",
        "train: /content/SportsMOT/sportsmot_publish/dataset/yolo/train/images\n",
        "val: /content/SportsMOT/sportsmot_publish/dataset/yolo/val/images\n",
        "test: /content/SportsMOT/sportsmot_publish/dataset/yolo/test/images\n",
        "\n",
        "names:\n",
        "  0: player\n",
        "  1: ball\n",
        "\"\"\"\n",
        "\n",
        "yaml_path = \"/content/SportsMOT/sportsmot_publish/dataset/yolo/dataset.yaml\"\n",
        "os.makedirs(os.path.dirname(yaml_path), exist_ok=True)\n",
        "\n",
        "with open(yaml_path, \"w\") as f:\n",
        "    f.write(dataset_yaml)\n",
        "\n",
        "print(f\"Dataset configuration updated at {yaml_path}.\")"
      ],
      "metadata": {
        "id": "LXOxjgYAPYzE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Train YOLO"
      ],
      "metadata": {
        "id": "1PGxmV8rKEqz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Load Data from Drive to Colab to Run"
      ],
      "metadata": {
        "id": "GHCSz_opKHp5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# !cp -r /content/drive/MyDrive/yolo /content/"
      ],
      "metadata": {
        "id": "yYHFWFhtANzg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "I first ran it for 15 epochs, then did it for 5 epochs. So it ran for 20 epochs."
      ],
      "metadata": {
        "id": "nPbV6ePT3gjc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from ultralytics import YOLO\n",
        "data_path = \"/content/SportsMOT/sportsmot_publish/dataset/yolo/dataset.yaml\"\n",
        "\n",
        "model = YOLO(\"yolov8s.pt\")\n",
        "\n",
        "model.train(data=data_path, epochs=15, imgsz=720, device=\"cuda\")\n",
        "\n",
        "!tensorboard --logdir runs/detect/train\n"
      ],
      "metadata": {
        "id": "SMweY1KMJ5Df"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Copy the trained model to Google Drive\n",
        "!cp runs/detect/train3/weights/best.pt /content/drive/MyDrive/yolo/best.pt"
      ],
      "metadata": {
        "id": "1DnVgEY0erzM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Load training results\n",
        "metrics = pd.read_csv(\"runs/detect/train/results.csv\")\n",
        "\n",
        "# Extract values\n",
        "epochs = metrics[\"epoch\"]\n",
        "train_loss = metrics[\"train/box_loss\"]\n",
        "val_loss = metrics[\"val/box_loss\"]\n",
        "map50 = metrics[\"metrics/mAP_50\"]\n",
        "map50_95 = metrics[\"metrics/mAP_50-95\"]\n",
        "\n",
        "# Plot loss curves\n",
        "plt.figure(figsize=(10, 5))\n",
        "plt.plot(epochs, train_loss, label=\"Train Loss\")\n",
        "plt.plot(epochs, val_loss, label=\"Validation Loss\")\n",
        "plt.xlabel(\"Epochs\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.title(\"Training & Validation Loss\")\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "# Plot accuracy curves\n",
        "plt.figure(figsize=(10, 5))\n",
        "plt.plot(epochs, map50, label=\"mAP@50\")\n",
        "plt.plot(epochs, map50_95, label=\"mAP@50-95\")\n",
        "plt.xlabel(\"Epochs\")\n",
        "plt.ylabel(\"mAP Score\")\n",
        "plt.title(\"Mean Average Precision (mAP) Over Epochs\")\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "fc9_-do1P-67"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "metrics = model.val(data=data_path)\n",
        "print(f\"mAP@50: {metrics['metrics/mAP_50']:.4f}\")\n",
        "print(f\"mAP@50-95: {metrics['metrics/mAP_50-95']:.4f}\")\n",
        "print(f\"Precision: {metrics['metrics/precision']:.4f}\")\n",
        "print(f\"Recall: {metrics['metrics/recall']:.4f}\")"
      ],
      "metadata": {
        "id": "AL9flXYIP-4q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Run inference on test images\n",
        "model.predict(source=\"/content/SportsMOT/sportsmot_publish/yolo/test/images\", save=True, conf=0.5)\n",
        "\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Load and display a sample image with predictions\n",
        "img_path = \"runs/detect/predict/image1.jpg\"\n",
        "image = cv2.imread(img_path)\n",
        "image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "plt.figure(figsize=(10, 5))\n",
        "plt.imshow(image)\n",
        "plt.axis(\"off\")\n",
        "plt.title(\"YOLOv8 Predictions on Sample Frame\")\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "oDibVebhP-l8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## SOT"
      ],
      "metadata": {
        "id": "khHqZXvY6fxW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "import glob\n",
        "\n",
        "# Path to the folder containing test images\n",
        "test_folder = \"/content/SportsMOT/sportsmot_publish/yolo/test/images\"\n",
        "\n",
        "# Get all image filenames\n",
        "image_files = sorted(glob.glob(os.path.join(test_folder, \"*.jpg\")))\n",
        "\n",
        "# Ensure correct ordering by sorting numerically\n",
        "image_files.sort(key=lambda x: int(x.split(\"_\")[-1].split(\".\")[0]))\n",
        "\n",
        "print(f\"Total frames found: {len(image_files)}\")\n",
        "print(f\"First frame: {image_files[0]}\")\n",
        "print(f\"Last frame: {image_files[-1]}\")"
      ],
      "metadata": {
        "id": "xmN6iDjb6kRh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Read the first frame\n",
        "first_frame = cv2.imread(image_files[0])\n",
        "\n",
        "# Manually select the object to track\n",
        "bbox = cv2.selectROI(\"Select Object to Track\", first_frame, fromCenter=False, showCrosshair=True)\n",
        "\n",
        "# Initialize CSRT Tracker\n",
        "tracker = cv2.TrackerCSRT_create()\n",
        "tracker.init(first_frame, bbox)\n",
        "\n",
        "cv2.destroyAllWindows()"
      ],
      "metadata": {
        "id": "9CmGfVMr6sdG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# List to store object trajectory\n",
        "trajectory = []\n",
        "\n",
        "for img_path in image_files:\n",
        "    frame = cv2.imread(img_path)\n",
        "\n",
        "    # Update tracker\n",
        "    success, bbox = tracker.update(frame)\n",
        "\n",
        "    if success:\n",
        "        x, y, w, h = map(int, bbox)\n",
        "        center = (x + w // 2, y + h // 2)\n",
        "        trajectory.append(center)\n",
        "\n",
        "        # Draw bounding box\n",
        "        cv2.rectangle(frame, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
        "        cv2.circle(frame, center, 3, (0, 0, 255), -1)\n",
        "\n",
        "    # Draw trajectory path\n",
        "    for i in range(1, len(trajectory)):\n",
        "        cv2.line(frame, trajectory[i - 1], trajectory[i], (255, 0, 0), 2)\n",
        "\n",
        "    # Display frame\n",
        "    cv2.imshow(\"Object Tracking\", frame)\n",
        "    if cv2.waitKey(25) & 0xFF == ord(\"q\"):\n",
        "        break\n",
        "\n",
        "cv2.destroyAllWindows()"
      ],
      "metadata": {
        "id": "Odg43Asj6wyr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "output_video_path = \"/content/tracking_output.avi\"\n",
        "frame_size = cv2.imread(image_files[0]).shape[1::-1]  # Get frame dimensions (width, height)\n",
        "\n",
        "# Define video writer\n",
        "out = cv2.VideoWriter(output_video_path, cv2.VideoWriter_fourcc(*\"XVID\"), 30, frame_size)\n",
        "\n",
        "for img_path in image_files:\n",
        "    frame = cv2.imread(img_path)\n",
        "    success, bbox = tracker.update(frame)\n",
        "\n",
        "    if success:\n",
        "        x, y, w, h = map(int, bbox)\n",
        "        center = (x + w // 2, y + h // 2)\n",
        "        trajectory.append(center)\n",
        "\n",
        "        # Draw bounding box and trajectory\n",
        "        cv2.rectangle(frame, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
        "        cv2.circle(frame, center, 3, (0, 0, 255), -1)\n",
        "        for i in range(1, len(trajectory)):\n",
        "            cv2.line(frame, trajectory[i - 1], trajectory[i], (255, 0, 0), 2)\n",
        "\n",
        "    out.write(frame)\n",
        "\n",
        "out.release()\n",
        "print(f\"Tracking video saved at {output_video_path}\")\n"
      ],
      "metadata": {
        "id": "OaIdikfl7GD2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Create an empty heatmap\n",
        "heatmap = np.zeros((720, 1280))\n",
        "\n",
        "# Increase heatmap intensity at tracked positions\n",
        "for (x, y) in trajectory:\n",
        "    heatmap[y, x] += 1\n",
        "\n",
        "# Display heatmap\n",
        "plt.figure(figsize=(10, 5))\n",
        "sns.heatmap(heatmap, cmap=\"hot\", cbar=True)\n",
        "plt.title(\"Object Movement Heatmap\")\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "se_xUVI17GBP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "d6Gy36NK7F-o"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}